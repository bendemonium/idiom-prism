{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba1fa863-ef48-4859-99d5-008b192a18db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from io import StringIO\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f7cb0a-a431-469d-869d-c936479912a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.ef.edu/english-resources/english-idioms/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12131968-91db-4a3c-aae8-27c42ca99fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04cfd26c-57e0-414a-958c-1ef62b3781ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfcd5452-18a5-4ec7-92a1-384a950f7c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = soup.find_all('table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b1b2c4-058a-4d1b-a8ee-3704883a9fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenated table:\n",
      "                                                 Idiom  \\\n",
      "0                               A blessing in disguise   \n",
      "1                                       A dime a dozen   \n",
      "2                                 Beat around the bush   \n",
      "3                               Better late than never   \n",
      "4                                      Bite the bullet   \n",
      "..                                                 ...   \n",
      "150                            Well begun is half done   \n",
      "151                             When it rains it pours   \n",
      "152  You can catch more flies with honey than you c...   \n",
      "153  You can lead a horse to water, but you can't m...   \n",
      "154  You can't make an omelet without breaking some...   \n",
      "\n",
      "                                               Meaning                  Usage  \n",
      "0                a good thing that seemed bad at first  as part of a sentence  \n",
      "1                                     Something common  as part of a sentence  \n",
      "2    Avoid saying what you mean, usually because it...  as part of a sentence  \n",
      "3        Better to arrive late than not to come at all              by itself  \n",
      "4    To get something over with because it is inevi...  as part of a sentence  \n",
      "..                                                 ...                    ...  \n",
      "150                  Getting a good start is important              by itself  \n",
      "151                  Everything is going wrong at once              by itself  \n",
      "152             You'll get what you want by being nice              by itself  \n",
      "153  You can't force someone to make the right deci...              by itself  \n",
      "154           There's always a cost to doing something              by itself  \n",
      "\n",
      "[155 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "all_dfs = []\n",
    "\n",
    "# Loop through all tables and convert them to pandas DataFrames\n",
    "for table in tables:\n",
    "    # Convert the table to a string and wrap it with StringIO\n",
    "    table_html = StringIO(str(table))\n",
    "    df = pd.read_html(table_html)[0]\n",
    "    all_dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames\n",
    "if all_dfs:\n",
    "    result = pd.concat(all_dfs, ignore_index=True)\n",
    "    print(\"Concatenated table:\")\n",
    "    print(result)\n",
    "else:\n",
    "    print(\"No tables found on the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "818124ee-7719-46a2-b9ae-57c9bf9213c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_idioms = result.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eab1fa2-2294-489b-8778-a15f5be10141",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_idioms['Transliteration'] = en_idioms['Idiom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59b224d1-b735-46da-8201-859ef16840f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idiom</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Transliteration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A blessing in disguise</td>\n",
       "      <td>a good thing that seemed bad at first</td>\n",
       "      <td>A blessing in disguise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A dime a dozen</td>\n",
       "      <td>Something common</td>\n",
       "      <td>A dime a dozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beat around the bush</td>\n",
       "      <td>Avoid saying what you mean, usually because it...</td>\n",
       "      <td>Beat around the bush</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Better late than never</td>\n",
       "      <td>Better to arrive late than not to come at all</td>\n",
       "      <td>Better late than never</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bite the bullet</td>\n",
       "      <td>To get something over with because it is inevi...</td>\n",
       "      <td>Bite the bullet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Well begun is half done</td>\n",
       "      <td>Getting a good start is important</td>\n",
       "      <td>Well begun is half done</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>When it rains it pours</td>\n",
       "      <td>Everything is going wrong at once</td>\n",
       "      <td>When it rains it pours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>You can catch more flies with honey than you c...</td>\n",
       "      <td>You'll get what you want by being nice</td>\n",
       "      <td>You can catch more flies with honey than you c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>You can lead a horse to water, but you can't m...</td>\n",
       "      <td>You can't force someone to make the right deci...</td>\n",
       "      <td>You can lead a horse to water, but you can't m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>You can't make an omelet without breaking some...</td>\n",
       "      <td>There's always a cost to doing something</td>\n",
       "      <td>You can't make an omelet without breaking some...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Idiom  \\\n",
       "0                               A blessing in disguise   \n",
       "1                                       A dime a dozen   \n",
       "2                                 Beat around the bush   \n",
       "3                               Better late than never   \n",
       "4                                      Bite the bullet   \n",
       "..                                                 ...   \n",
       "150                            Well begun is half done   \n",
       "151                             When it rains it pours   \n",
       "152  You can catch more flies with honey than you c...   \n",
       "153  You can lead a horse to water, but you can't m...   \n",
       "154  You can't make an omelet without breaking some...   \n",
       "\n",
       "                                               Meaning  \\\n",
       "0                a good thing that seemed bad at first   \n",
       "1                                     Something common   \n",
       "2    Avoid saying what you mean, usually because it...   \n",
       "3        Better to arrive late than not to come at all   \n",
       "4    To get something over with because it is inevi...   \n",
       "..                                                 ...   \n",
       "150                  Getting a good start is important   \n",
       "151                  Everything is going wrong at once   \n",
       "152             You'll get what you want by being nice   \n",
       "153  You can't force someone to make the right deci...   \n",
       "154           There's always a cost to doing something   \n",
       "\n",
       "                                       Transliteration  \n",
       "0                               A blessing in disguise  \n",
       "1                                       A dime a dozen  \n",
       "2                                 Beat around the bush  \n",
       "3                               Better late than never  \n",
       "4                                      Bite the bullet  \n",
       "..                                                 ...  \n",
       "150                            Well begun is half done  \n",
       "151                             When it rains it pours  \n",
       "152  You can catch more flies with honey than you c...  \n",
       "153  You can lead a horse to water, but you can't m...  \n",
       "154  You can't make an omelet without breaking some...  \n",
       "\n",
       "[155 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_idioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5992b7bf-d7c5-41d7-95f9-d502d81250be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ridhibandaru/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59aa0009-853b-40fa-8dbf-5abc291a740e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
    "nltk_stopwords = set(stopwords.words('english'))\n",
    "combined_stopwords = spacy_stopwords.union(nltk_stopwords)\n",
    "\n",
    "# Words to keep even if they're in the stop word list\n",
    "important_words = {'not', 'no', 'very', 'too', 'only', 'just'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a22b92c-dfa0-4ce6-9847-2f9e6550b6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    \n",
    "    # Process the text with spaCy\n",
    "    doc = nlp(text.lower())\n",
    "    \n",
    "    # Filter out stop words, but keep important words and punctuation\n",
    "    filtered_words = [token.text for token in doc if token.text not in combined_stopwords \n",
    "                      or token.text in important_words or token.is_punct]\n",
    "    \n",
    "    # Rejoin the words\n",
    "    return ' '.join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c2c93c8-1e49-4e74-803b-f705ed58af35",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_idioms['MeaningStripped'] = en_idioms['Meaning'].apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7587018b-a477-4af4-b8b9-922c80a28f81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idiom</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>MeaningStripped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A blessing in disguise</td>\n",
       "      <td>a good thing that seemed bad at first</td>\n",
       "      <td>A blessing in disguise</td>\n",
       "      <td>good thing bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A dime a dozen</td>\n",
       "      <td>Something common</td>\n",
       "      <td>A dime a dozen</td>\n",
       "      <td>common</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beat around the bush</td>\n",
       "      <td>Avoid saying what you mean, usually because it...</td>\n",
       "      <td>Beat around the bush</td>\n",
       "      <td>avoid saying mean , usually uncomfortable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Better late than never</td>\n",
       "      <td>Better to arrive late than not to come at all</td>\n",
       "      <td>Better late than never</td>\n",
       "      <td>better arrive late not come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bite the bullet</td>\n",
       "      <td>To get something over with because it is inevi...</td>\n",
       "      <td>Bite the bullet</td>\n",
       "      <td>inevitable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Well begun is half done</td>\n",
       "      <td>Getting a good start is important</td>\n",
       "      <td>Well begun is half done</td>\n",
       "      <td>getting good start important</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>When it rains it pours</td>\n",
       "      <td>Everything is going wrong at once</td>\n",
       "      <td>When it rains it pours</td>\n",
       "      <td>going wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>You can catch more flies with honey than you c...</td>\n",
       "      <td>You'll get what you want by being nice</td>\n",
       "      <td>You can catch more flies with honey than you c...</td>\n",
       "      <td>want nice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>You can lead a horse to water, but you can't m...</td>\n",
       "      <td>You can't force someone to make the right deci...</td>\n",
       "      <td>You can lead a horse to water, but you can't m...</td>\n",
       "      <td>force right decision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>You can't make an omelet without breaking some...</td>\n",
       "      <td>There's always a cost to doing something</td>\n",
       "      <td>You can't make an omelet without breaking some...</td>\n",
       "      <td>cost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Idiom  \\\n",
       "0                               A blessing in disguise   \n",
       "1                                       A dime a dozen   \n",
       "2                                 Beat around the bush   \n",
       "3                               Better late than never   \n",
       "4                                      Bite the bullet   \n",
       "..                                                 ...   \n",
       "150                            Well begun is half done   \n",
       "151                             When it rains it pours   \n",
       "152  You can catch more flies with honey than you c...   \n",
       "153  You can lead a horse to water, but you can't m...   \n",
       "154  You can't make an omelet without breaking some...   \n",
       "\n",
       "                                               Meaning  \\\n",
       "0                a good thing that seemed bad at first   \n",
       "1                                     Something common   \n",
       "2    Avoid saying what you mean, usually because it...   \n",
       "3        Better to arrive late than not to come at all   \n",
       "4    To get something over with because it is inevi...   \n",
       "..                                                 ...   \n",
       "150                  Getting a good start is important   \n",
       "151                  Everything is going wrong at once   \n",
       "152             You'll get what you want by being nice   \n",
       "153  You can't force someone to make the right deci...   \n",
       "154           There's always a cost to doing something   \n",
       "\n",
       "                                       Transliteration  \\\n",
       "0                               A blessing in disguise   \n",
       "1                                       A dime a dozen   \n",
       "2                                 Beat around the bush   \n",
       "3                               Better late than never   \n",
       "4                                      Bite the bullet   \n",
       "..                                                 ...   \n",
       "150                            Well begun is half done   \n",
       "151                             When it rains it pours   \n",
       "152  You can catch more flies with honey than you c...   \n",
       "153  You can lead a horse to water, but you can't m...   \n",
       "154  You can't make an omelet without breaking some...   \n",
       "\n",
       "                               MeaningStripped  \n",
       "0                               good thing bad  \n",
       "1                                       common  \n",
       "2    avoid saying mean , usually uncomfortable  \n",
       "3                  better arrive late not come  \n",
       "4                                   inevitable  \n",
       "..                                         ...  \n",
       "150               getting good start important  \n",
       "151                                going wrong  \n",
       "152                                  want nice  \n",
       "153                       force right decision  \n",
       "154                                       cost  \n",
       "\n",
       "[155 rows x 4 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_idioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "485e1d99-a7fa-4689-802e-3be65b2c66a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cc2ef081-fa8c-4031-b275-71b303decb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = en_idioms['Meaning'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7380ad55-4442-43a6-a48b-e0f29667ff3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Topic  Count                                  Name  \\\n",
      "0     -1     84           -1_good_just_problem_better   \n",
      "1      0     14                 0_dont_hes_late_youre   \n",
      "2      1     41              1_things_good_work_doing   \n",
      "3      2     16  2_people_negative_understand_usually   \n",
      "\n",
      "                                      Representation  \\\n",
      "0  [good, just, problem, better, dont, secret, st...   \n",
      "1  [dont, hes, late, youre, thinking, hes dumb, d...   \n",
      "2  [things, good, work, doing, money, things goin...   \n",
      "3  [people, negative, understand, usually, proble...   \n",
      "\n",
      "                                 Representative_Docs  \n",
      "0  [The big issue, the problem people are avoidin...  \n",
      "1  [It's too late, It's too late, The son is like...  \n",
      "2  [Things are going from bad to worse, Things ar...  \n",
      "3  [Understand the situation (usually negative), ...  \n",
      "                                              Document  Topic  \\\n",
      "0                a good thing that seemed bad at first      1   \n",
      "1                                     Something common     -1   \n",
      "2    Avoid saying what you mean, usually because it...     -1   \n",
      "3        Better to arrive late than not to come at all     -1   \n",
      "4    To get something over with because it is inevi...      1   \n",
      "..                                                 ...    ...   \n",
      "150                  Getting a good start is important      1   \n",
      "151                  Everything is going wrong at once     -1   \n",
      "152             You'll get what you want by being nice      2   \n",
      "153  You can't force someone to make the right deci...      1   \n",
      "154           There's always a cost to doing something      1   \n",
      "\n",
      "                                     Name  \\\n",
      "0                1_things_good_work_doing   \n",
      "1             -1_good_just_problem_better   \n",
      "2             -1_good_just_problem_better   \n",
      "3             -1_good_just_problem_better   \n",
      "4                1_things_good_work_doing   \n",
      "..                                    ...   \n",
      "150              1_things_good_work_doing   \n",
      "151           -1_good_just_problem_better   \n",
      "152  2_people_negative_understand_usually   \n",
      "153              1_things_good_work_doing   \n",
      "154              1_things_good_work_doing   \n",
      "\n",
      "                                        Representation  \\\n",
      "0    [things, good, work, doing, money, things goin...   \n",
      "1    [good, just, problem, better, dont, secret, st...   \n",
      "2    [good, just, problem, better, dont, secret, st...   \n",
      "3    [good, just, problem, better, dont, secret, st...   \n",
      "4    [things, good, work, doing, money, things goin...   \n",
      "..                                                 ...   \n",
      "150  [things, good, work, doing, money, things goin...   \n",
      "151  [good, just, problem, better, dont, secret, st...   \n",
      "152  [people, negative, understand, usually, proble...   \n",
      "153  [things, good, work, doing, money, things goin...   \n",
      "154  [things, good, work, doing, money, things goin...   \n",
      "\n",
      "                                   Representative_Docs  \\\n",
      "0    [Things are going from bad to worse, Things ar...   \n",
      "1    [The big issue, the problem people are avoidin...   \n",
      "2    [The big issue, the problem people are avoidin...   \n",
      "3    [The big issue, the problem people are avoidin...   \n",
      "4    [Things are going from bad to worse, Things ar...   \n",
      "..                                                 ...   \n",
      "150  [Things are going from bad to worse, Things ar...   \n",
      "151  [The big issue, the problem people are avoidin...   \n",
      "152  [Understand the situation (usually negative), ...   \n",
      "153  [Things are going from bad to worse, Things ar...   \n",
      "154  [Things are going from bad to worse, Things ar...   \n",
      "\n",
      "                                           Top_n_words  Probability  \\\n",
      "0    things - good - work - doing - money - things ...     0.989697   \n",
      "1    good - just - problem - better - dont - secret...     0.000000   \n",
      "2    good - just - problem - better - dont - secret...     0.000000   \n",
      "3    good - just - problem - better - dont - secret...     0.000000   \n",
      "4    things - good - work - doing - money - things ...     0.966208   \n",
      "..                                                 ...          ...   \n",
      "150  things - good - work - doing - money - things ...     0.997285   \n",
      "151  good - just - problem - better - dont - secret...     0.000000   \n",
      "152  people - negative - understand - usually - pro...     1.000000   \n",
      "153  things - good - work - doing - money - things ...     1.000000   \n",
      "154  things - good - work - doing - money - things ...     1.000000   \n",
      "\n",
      "     Representative_document  \n",
      "0                      False  \n",
      "1                      False  \n",
      "2                      False  \n",
      "3                      False  \n",
      "4                      False  \n",
      "..                       ...  \n",
      "150                    False  \n",
      "151                    False  \n",
      "152                    False  \n",
      "153                    False  \n",
      "154                    False  \n",
      "\n",
      "[155 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_model = CountVectorizer(ngram_range=(1, 2), stop_words=\"english\")\n",
    "topic_model = BERTopic(vectorizer_model=vectorizer_model, nr_topics=10)\n",
    "\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "# Get the top topics\n",
    "print(topic_model.get_topic_info())\n",
    "\n",
    "# Get the topics for specific documents\n",
    "print(topic_model.get_document_info(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "23bdeb45-622b-4e56-a4fb-15d57b088c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_info = topic_model.get_document_info(docs)\n",
    "\n",
    "# Add the topic assignments to your DataFrame\n",
    "en_idioms['Topic'] = document_info['Topic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89555487-c58d-4383-8ddd-a5e7e8adb699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Idiom</th>\n",
       "      <th>Meaning</th>\n",
       "      <th>Transliteration</th>\n",
       "      <th>MeaningStripped</th>\n",
       "      <th>Topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A blessing in disguise</td>\n",
       "      <td>a good thing that seemed bad at first</td>\n",
       "      <td>A blessing in disguise</td>\n",
       "      <td>good thing bad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A dime a dozen</td>\n",
       "      <td>Something common</td>\n",
       "      <td>A dime a dozen</td>\n",
       "      <td>common</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beat around the bush</td>\n",
       "      <td>Avoid saying what you mean, usually because it...</td>\n",
       "      <td>Beat around the bush</td>\n",
       "      <td>avoid saying mean , usually uncomfortable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Better late than never</td>\n",
       "      <td>Better to arrive late than not to come at all</td>\n",
       "      <td>Better late than never</td>\n",
       "      <td>better arrive late not come</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bite the bullet</td>\n",
       "      <td>To get something over with because it is inevi...</td>\n",
       "      <td>Bite the bullet</td>\n",
       "      <td>inevitable</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Well begun is half done</td>\n",
       "      <td>Getting a good start is important</td>\n",
       "      <td>Well begun is half done</td>\n",
       "      <td>getting good start important</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>When it rains it pours</td>\n",
       "      <td>Everything is going wrong at once</td>\n",
       "      <td>When it rains it pours</td>\n",
       "      <td>going wrong</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>You can catch more flies with honey than you c...</td>\n",
       "      <td>You'll get what you want by being nice</td>\n",
       "      <td>You can catch more flies with honey than you c...</td>\n",
       "      <td>want nice</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>You can lead a horse to water, but you can't m...</td>\n",
       "      <td>You can't force someone to make the right deci...</td>\n",
       "      <td>You can lead a horse to water, but you can't m...</td>\n",
       "      <td>force right decision</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>You can't make an omelet without breaking some...</td>\n",
       "      <td>There's always a cost to doing something</td>\n",
       "      <td>You can't make an omelet without breaking some...</td>\n",
       "      <td>cost</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>155 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Idiom  \\\n",
       "0                               A blessing in disguise   \n",
       "1                                       A dime a dozen   \n",
       "2                                 Beat around the bush   \n",
       "3                               Better late than never   \n",
       "4                                      Bite the bullet   \n",
       "..                                                 ...   \n",
       "150                            Well begun is half done   \n",
       "151                             When it rains it pours   \n",
       "152  You can catch more flies with honey than you c...   \n",
       "153  You can lead a horse to water, but you can't m...   \n",
       "154  You can't make an omelet without breaking some...   \n",
       "\n",
       "                                               Meaning  \\\n",
       "0                a good thing that seemed bad at first   \n",
       "1                                     Something common   \n",
       "2    Avoid saying what you mean, usually because it...   \n",
       "3        Better to arrive late than not to come at all   \n",
       "4    To get something over with because it is inevi...   \n",
       "..                                                 ...   \n",
       "150                  Getting a good start is important   \n",
       "151                  Everything is going wrong at once   \n",
       "152             You'll get what you want by being nice   \n",
       "153  You can't force someone to make the right deci...   \n",
       "154           There's always a cost to doing something   \n",
       "\n",
       "                                       Transliteration  \\\n",
       "0                               A blessing in disguise   \n",
       "1                                       A dime a dozen   \n",
       "2                                 Beat around the bush   \n",
       "3                               Better late than never   \n",
       "4                                      Bite the bullet   \n",
       "..                                                 ...   \n",
       "150                            Well begun is half done   \n",
       "151                             When it rains it pours   \n",
       "152  You can catch more flies with honey than you c...   \n",
       "153  You can lead a horse to water, but you can't m...   \n",
       "154  You can't make an omelet without breaking some...   \n",
       "\n",
       "                               MeaningStripped  Topic  \n",
       "0                               good thing bad      0  \n",
       "1                                       common     -1  \n",
       "2    avoid saying mean , usually uncomfortable      0  \n",
       "3                  better arrive late not come     -1  \n",
       "4                                   inevitable     -1  \n",
       "..                                         ...    ...  \n",
       "150               getting good start important     -1  \n",
       "151                                going wrong     -1  \n",
       "152                                  want nice     -1  \n",
       "153                       force right decision     -1  \n",
       "154                                       cost     -1  \n",
       "\n",
       "[155 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_idioms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e9b5272-303f-46bd-9c91-5d5790efbeab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3096fa0e464e9a8f476209fab0a920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc78a88281c454c993fe8492f7d5432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cac8485505db4334b0e2fa3bcca18b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed6c45eb9cd42c4b2f5d5d78d25f3ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0593affcfa341b395ac8267a6f73f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:515: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Idiom                                        T5_Response\n",
      "0  A blessing in disguise  in Hindi: in Hindi: A blessing in disguise. in...\n",
      "1          A dime a dozen  in Hindi: A dime a dozen. in Hindi: A dime a d...\n",
      "2    Beat around the bush  in Hindi: in Hindi: in Hindi: in Hindi: in Hin...\n",
      "3  Better late than never  in Hindi: in Hindi: in Hindi: in Hindi:: Bette...\n",
      "4         Bite the bullet  in Hindi: in Hindi: in Hindi: in Hindi: Bite t...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "import torch\n",
    "\n",
    "# Load the T5 model and tokenizer\n",
    "model_name = \"t5-base\"  # You can use \"t5-base\" or \"t5-large\" for better results, but they require more memory\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv('idioms_en.csv')\n",
    "\n",
    "# The prompt you want to use\n",
    "prompt = \"Find the equivalent of this idiom in Hindi: \"\n",
    "\n",
    "def generate_response(input_text):\n",
    "    input_text = prompt + input_text\n",
    "    input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    \n",
    "    outputs = model.generate(input_ids, max_length=100, num_return_sequences=1, temperature=0.7)\n",
    "    \n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return response\n",
    "\n",
    "# Apply the function to create a new column\n",
    "df['T5_Response'] = df['Idiom'].apply(generate_response)\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv('output_with_t5_responses.csv', index=False)\n",
    "\n",
    "print(df[['Idiom', 'T5_Response']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77507869-bbab-4350-84a9-8d0de5d087b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS (GPU) device\n",
      "                    Idiom             Translated\n",
      "0  A blessing in disguise  आशीर्वाद में आशीर्वाद\n",
      "1          A dime a dozen          दसवीं शताब्दी\n",
      "2    Beat around the bush   बश के चारों ओर घूमना\n",
      "3  Better late than never  कभी नहीं देर से बेहतर\n",
      "4         Bite the bullet          गेंद को मारना\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"Using MPS (GPU) device\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"Using CUDA (GPU) device\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not found, using CPU\")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"facebook/m2m100_418M\"  # You can also use \"facebook/m2m100_1.2B\" for better results\n",
    "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(model_name).to(device)\n",
    "\n",
    "# Load your DataFrame\n",
    "df = pd.read_csv('idioms_en.csv')\n",
    "\n",
    "def translate_text(text, src_lang=\"en\", tgt_lang=\"hi\"):\n",
    "    # Set the source language\n",
    "    tokenizer.src_lang = src_lang\n",
    "\n",
    "    # Tokenize the input text\n",
    "    encoded_input = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # Generate translation\n",
    "    generated_tokens = model.generate(\n",
    "        **encoded_input,\n",
    "        forced_bos_token_id=tokenizer.get_lang_id(tgt_lang)\n",
    "    )\n",
    "\n",
    "    # Decode the generated tokens to text\n",
    "    translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    return translation[0]\n",
    "\n",
    "# Apply the translation function to create a new column\n",
    "df['Translated'] = df['Idiom'].apply(lambda x: translate_text(x, src_lang=\"en\", tgt_lang=\"hi\"))\n",
    "\n",
    "# Save the updated DataFrame\n",
    "df.to_csv('output_with_translations.csv', index=False)\n",
    "\n",
    "print(df[['Idiom', 'Translated']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de61fc21-2fca-41b9-bc0e-f0fe09f899ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a0b07521ac40ecbcf771498ea30d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b1d021e66940cf83ab5c535261b502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "source.spm:   0%|          | 0.00/812k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e5a38e9e3d4c19b175b9e4e07271b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "target.spm:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1ba13bbf3a48fbad834eaebc2f370c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f24834ac4d423387d9e869ecd234cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cef1e72316b4d7b9a50abf4a98c79bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/306M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91e78442cb14bf0b144ce1eae2b39c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "यह डाकुओं और कुत्तों की बारिश है\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "model_name = f\"Helsinki-NLP/opus-mt-en-hi\"  # Change language pair as needed\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "def translate(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True)\n",
    "    outputs = model.generate(**inputs)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# Test\n",
    "idiom = \"It's raining cats and dogs\"\n",
    "print(translate(idiom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "824dd852-0fd6-4d48-b022-b63bc8b9bde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Multilingual model for transliteration\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MB\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(121.0 of 121.0)\u001b[39m |################| Elapsed Time: 0:00:37 Time:  0:00:370003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succefully Downloaded to: /opt/anaconda3/lib/python3.11/site-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0/model.zip\n",
      "Models downloaded to: /opt/anaconda3/lib/python3.11/site-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0\n",
      "NOTE: When uninstalling this library, REMEMBER to delete the models manually\n",
      "Downloading language model probablitites dictionaries for rescoring module\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MB\u001b[38;2;0;255;0m100%\u001b[39m \u001b[38;2;0;255;0m(812.0 of 812.0)\u001b[39m |################| Elapsed Time: 0:04:28 Time:  0:04:280222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succefully Downloaded to: /opt/anaconda3/lib/python3.11/site-packages/ai4bharat/transliteration/transformer/models/en2indic/v1.0/dicts.zip\n",
      "Initializing Multilingual model for transliteration\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "mutable default <class 'fairseq.dataclass.configs.CommonConfig'> for field common is not allowed: use default_factory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mai4bharat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransliteration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XlitEngine\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the transliteration engine\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m e \u001b[38;5;241m=\u001b[39m XlitEngine(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhi\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# 'hi' for Hindi, change as needed\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtranslate_indic\u001b[39m(text, src_lang, tgt_lang):\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# This is a simplified example. You'd need to implement the actual translation logic\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# using the IndicTrans model or API\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     translated \u001b[38;5;241m=\u001b[39m some_indic_trans_function(text, src_lang, tgt_lang)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ai4bharat/transliteration/xlit_src.py:9\u001b[0m, in \u001b[0;36mXlitEngine\u001b[0;34m(lang2use, beam_width, rescore, model_type, src_script_type)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m src_script_type \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroman\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XlitEngineTransformer_En2Indic\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m XlitEngineTransformer_En2Indic(lang2use, beam_width\u001b[38;5;241m=\u001b[39mbeam_width, rescore\u001b[38;5;241m=\u001b[39mrescore)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m src_script_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindic\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XlitEngineTransformer_Indic2En\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ai4bharat/transliteration/transformer/en2indic.py:78\u001b[0m, in \u001b[0;36mXlitEngineTransformer_En2Indic.__init__\u001b[0;34m(self, lang2use, beam_width, rescore)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     dicts_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(models_path, beam_width\u001b[38;5;241m=\u001b[39mbeam_width, rescore\u001b[38;5;241m=\u001b[39mrescore)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ai4bharat/transliteration/transformer/base_engine.py:45\u001b[0m, in \u001b[0;36mBaseEngineTransformer.__init__\u001b[0;34m(self, models_path, beam_width, rescore)\u001b[0m\n\u001b[1;32m     42\u001b[0m     lang_pairs_csv \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mlang \u001b[38;5;28;01mfor\u001b[39;00m lang \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_supported_langs])\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# initialize the model\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcustom_interactive\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Transliterator\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransliterator \u001b[38;5;241m=\u001b[39m Transliterator(\n\u001b[1;32m     47\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_path, CHARS_FOLDER),\n\u001b[1;32m     48\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(models_path, MODEL_FILE),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m     beam \u001b[38;5;241m=\u001b[39m beam_width, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     52\u001b[0m )\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeam_width \u001b[38;5;241m=\u001b[39m beam_width\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/ai4bharat/transliteration/transformer/custom_interactive.py:23\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m checkpoint_utils, distributed_utils, options, tasks, utils\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclass\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FairseqConfig\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclass\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_namespace_to_omegaconf\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/fairseq/__init__.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpdb\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# backwards compatibility to support `from fairseq.X import Y`\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m distributed_utils\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m meters, metrics, progress_bar  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[1;32m     23\u001b[0m sys\u001b[38;5;241m.\u001b[39mmodules[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfairseq.distributed_utils\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m distributed_utils\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/fairseq/distributed/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed_timeout_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedTimeoutWrapper\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfully_sharded_data_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     fsdp_enable_wrap,\n\u001b[1;32m      9\u001b[0m     fsdp_wrap,\n\u001b[1;32m     10\u001b[0m     FullyShardedDataParallel,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy_distributed_data_parallel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LegacyDistributedDataParallel\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodule_proxy_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModuleProxyWrapper\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/fairseq/distributed/fully_sharded_data_parallel.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataclass\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DistributedTrainingConfig\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfairseq\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils \u001b[38;5;28;01mas\u001b[39;00m dist_utils\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/fairseq/dataclass/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfigs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FairseqDataclass\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstants\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChoiceEnum\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFairseqDataclass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChoiceEnum\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/fairseq/dataclass/configs.py:1104\u001b[0m\n\u001b[1;32m   1095\u001b[0m     ema_update_freq: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m field(\n\u001b[1;32m   1096\u001b[0m         default\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDo EMA update every this many model updates\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   1097\u001b[0m     )\n\u001b[1;32m   1098\u001b[0m     ema_fp32: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m field(\n\u001b[1;32m   1099\u001b[0m         default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1100\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhelp\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf true, store EMA model in fp32 even if model is in fp16\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m   1101\u001b[0m     )\n\u001b[0;32m-> 1104\u001b[0m \u001b[38;5;129m@dataclass\u001b[39m\n\u001b[1;32m   1105\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mFairseqConfig\u001b[39;00m(FairseqDataclass):\n\u001b[1;32m   1106\u001b[0m     common: CommonConfig \u001b[38;5;241m=\u001b[39m CommonConfig()\n\u001b[1;32m   1107\u001b[0m     common_eval: CommonEvalConfig \u001b[38;5;241m=\u001b[39m CommonEvalConfig()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/dataclasses.py:1230\u001b[0m, in \u001b[0;36mdataclass\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m wrap\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;66;03m# We're called as @dataclass without parens.\u001b[39;00m\n\u001b[0;32m-> 1230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(\u001b[38;5;28mcls\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/dataclasses.py:1220\u001b[0m, in \u001b[0;36mdataclass.<locals>.wrap\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;28mcls\u001b[39m):\n\u001b[0;32m-> 1220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _process_class(\u001b[38;5;28mcls\u001b[39m, init, \u001b[38;5;28mrepr\u001b[39m, eq, order, unsafe_hash,\n\u001b[1;32m   1221\u001b[0m                           frozen, match_args, kw_only, slots,\n\u001b[1;32m   1222\u001b[0m                           weakref_slot)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/dataclasses.py:958\u001b[0m, in \u001b[0;36m_process_class\u001b[0;34m(cls, init, repr, eq, order, unsafe_hash, frozen, match_args, kw_only, slots, weakref_slot)\u001b[0m\n\u001b[1;32m    955\u001b[0m         kw_only \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    956\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    957\u001b[0m         \u001b[38;5;66;03m# Otherwise it's a field of some type.\u001b[39;00m\n\u001b[0;32m--> 958\u001b[0m         cls_fields\u001b[38;5;241m.\u001b[39mappend(_get_field(\u001b[38;5;28mcls\u001b[39m, name, \u001b[38;5;28mtype\u001b[39m, kw_only))\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m cls_fields:\n\u001b[1;32m    961\u001b[0m     fields[f\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m f\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/dataclasses.py:815\u001b[0m, in \u001b[0;36m_get_field\u001b[0;34m(cls, a_name, a_type, default_kw_only)\u001b[0m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# For real fields, disallow mutable defaults.  Use unhashable as a proxy\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;66;03m# indicator for mutability.  Read the __hash__ attribute from the class,\u001b[39;00m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;66;03m# not the instance.\u001b[39;00m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39m_field_type \u001b[38;5;129;01mis\u001b[39;00m _FIELD \u001b[38;5;129;01mand\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdefault\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__hash__\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 815\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmutable default \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(f\u001b[38;5;241m.\u001b[39mdefault)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for field \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    816\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not allowed: use default_factory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "\u001b[0;31mValueError\u001b[0m: mutable default <class 'fairseq.dataclass.configs.CommonConfig'> for field common is not allowed: use default_factory"
     ]
    }
   ],
   "source": [
    "from indicnlp.transliterate.unicode_transliterate import UnicodeIndicTransliterator\n",
    "from ai4bharat.transliteration import XlitEngine\n",
    "\n",
    "# Initialize the transliteration engine\n",
    "e = XlitEngine(\"hi\")  # 'hi' for Hindi, change as needed\n",
    "\n",
    "def translate_indic(text, src_lang, tgt_lang):\n",
    "    # This is a simplified example. You'd need to implement the actual translation logic\n",
    "    # using the IndicTrans model or API\n",
    "    translated = some_indic_trans_function(text, src_lang, tgt_lang)\n",
    "    return translated\n",
    "\n",
    "# Example usage\n",
    "idiom = \"It's raining cats and dogs\"\n",
    "print(translate_indic(idiom, 'en', 'hi'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a4c81a4-fb8e-45b9-9ed4-4129ed764b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b674b603d7ef477b9123400072311d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2082505d3c26410bb5872d9686f5947c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "121ef315100a4d0fb5bedddf227189d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9108b5ce67c44f786538bbb1bf8cd41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cef8d5b4104ec68ec075ce4162ee3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5716c18a34cf4e7d90e257b8a41f6688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: The project was difficult, but John decided to bite the bullet and start working on it immediately.\n",
      "Translated: The project was difficult, but John decided to <idiom>bite the bullet</idiom>, and start working on it immediately.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "# Load a pre-trained model (you'd need to fine-tune this on your data)\n",
    "model_name = \"facebook/bart-large\"  # or another suitable model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "def context_aware_translate(text, idiom, context_window=50):\n",
    "    # Find the idiom in the text\n",
    "    idiom_start = text.index(idiom)\n",
    "    idiom_end = idiom_start + len(idiom)\n",
    "    \n",
    "    # Get context before and after the idiom\n",
    "    context_start = max(0, idiom_start - context_window)\n",
    "    context_end = min(len(text), idiom_end + context_window)\n",
    "    \n",
    "    # Create input with context and special tokens to highlight the idiom\n",
    "    input_text = (\n",
    "        f\"{text[context_start:idiom_start]}\"\n",
    "        f\"<idiom>{idiom}</idiom>\"\n",
    "        f\"{text[idiom_end:context_end]}\"\n",
    "    )\n",
    "    \n",
    "    # Tokenize and generate translation\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = model.generate(**inputs, max_length=150)\n",
    "    \n",
    "    # Decode and return the translation\n",
    "    translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return translation\n",
    "\n",
    "# Example usage\n",
    "full_text = \"The project was difficult, but John decided to bite the bullet and start working on it immediately.\"\n",
    "idiom = \"bite the bullet\"\n",
    "\n",
    "translated = context_aware_translate(full_text, idiom)\n",
    "print(f\"Original: {full_text}\")\n",
    "print(f\"Translated: {translated}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f3215c2-84a2-4010-9367-170ba0468731",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m\n\u001b[1;32m     43\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     44\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     45\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m     46\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtokenized_dataset,\n\u001b[1;32m     47\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1886\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1887\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1888\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1889\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1890\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2178\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2175\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2177\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 2178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(epoch_iterator):\n\u001b[1;32m   2179\u001b[0m     total_batched_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39minclude_num_input_tokens_seen:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/accelerate/data_loader.py:454\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# We iterate one batch ahead to check when we are at the end\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 454\u001b[0m     current_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:629\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py:672\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    671\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 672\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    673\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    674\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "# Prepare your dataset\n",
    "data = [\n",
    "    {\"input\": \"The project was difficult, but John decided to <idiom>bite the bullet</idiom> and start working on it immediately.\",\n",
    "     \"target\": \"प्रोजेक्ट कठिन था, लेकिन जॉन ने हिम्मत करके तुरंत काम शुरू करने का फैसला किया।\"},\n",
    "    # Add more examples...\n",
    "]\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Load a pre-trained model and tokenizer\n",
    "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Set up tokenizer for English input and Hindi output\n",
    "tokenizer.src_lang = \"en_XX\"\n",
    "tokenizer.tgt_lang = \"hi_IN\"\n",
    "\n",
    "# Tokenization function\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(examples[\"input\"].tolist(), max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        targets = tokenizer(examples[\"target\"].tolist(), max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    return {\"input_ids\": inputs[\"input_ids\"], \"attention_mask\": inputs[\"attention_mask\"], \"labels\": targets[\"input_ids\"]}\n",
    "\n",
    "# Tokenize the dataset\n",
    "tokenized_dataset = preprocess_function(df)\n",
    "\n",
    "# Set up training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "# Create Trainer instance\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4d7f4c-d7c8-49be-b42f-2d91357b9e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idiom: A blessing in disguise\n",
      "Similar idioms:\n",
      "                    Idiom                       Meaning\n",
      "40        A perfect storm  the worst possible situation\n",
      "31  To make matters worse          Make a problem worse\n",
      "\n",
      "Cluster statistics:\n",
      "cluster\n",
      "17    21\n",
      "1     21\n",
      "0     20\n",
      "13    19\n",
      "11    12\n",
      "16    11\n",
      "8      9\n",
      "2      6\n",
      "3      6\n",
      "12     4\n",
      "18     3\n",
      "5      3\n",
      "15     3\n",
      "6      3\n",
      "9      3\n",
      "10     3\n",
      "7      3\n",
      "14     3\n",
      "4      2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('idioms_en.csv')\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for the meanings\n",
    "embeddings = model.encode(df['Meaning'].tolist())\n",
    "\n",
    "# Determine optimal number of clusters using silhouette score\n",
    "silhouette_scores = []\n",
    "K = range(2, 20)\n",
    "for k in K:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(embeddings)\n",
    "    score = silhouette_score(embeddings, kmeans.labels_)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "optimal_k = K[np.argmax(silhouette_scores)]\n",
    "\n",
    "# Perform clustering with optimal K\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(embeddings)\n",
    "\n",
    "# Function to find similar idioms\n",
    "def find_similar_idioms(idiom_index, top_n=2):\n",
    "    cluster = df.loc[idiom_index, 'cluster']\n",
    "    cluster_idioms = df[df['cluster'] == cluster].index\n",
    "    idiom_embedding = embeddings[idiom_index]\n",
    "    similarities = [np.dot(idiom_embedding, embeddings[i]) / (np.linalg.norm(idiom_embedding) * np.linalg.norm(embeddings[i])) for i in cluster_idioms]\n",
    "    top_indices = np.argsort(similarities)[::-1][1:top_n+1]\n",
    "    return df.iloc[cluster_idioms[top_indices]]\n",
    "\n",
    "# Example usage\n",
    "example_idiom_index = 0\n",
    "similar_idioms = find_similar_idioms(example_idiom_index)\n",
    "print(f\"Idiom: {df.iloc[example_idiom_index]['Idiom']}\")\n",
    "print(\"Similar idioms:\")\n",
    "print(similar_idioms[['Idiom', 'Meaning']])\n",
    "\n",
    "# Print cluster statistics\n",
    "print(\"\\nCluster statistics:\")\n",
    "print(df['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca6e504b-d6c2-4832-b988-bc825be5979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Idiom: Give someone the benefit of the doubt\n",
      "Meaning: Trust what someone says\n",
      "\n",
      "Similar idioms:\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load your data\n",
    "df = pd.read_csv('idioms_en.csv')\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for the meanings\n",
    "embeddings = model.encode(df['Meaning'].tolist())\n",
    "\n",
    "# Function to find idioms with very similar meanings\n",
    "def find_similar_idioms(idiom_index, top_n=5, similarity_threshold=0.6):\n",
    "    idiom_embedding = embeddings[idiom_index].reshape(1, -1)\n",
    "    similarities = cosine_similarity(idiom_embedding, embeddings)[0]\n",
    "    \n",
    "    # Get indices of idioms above the similarity threshold, excluding the input idiom\n",
    "    similar_indices = np.where((similarities > similarity_threshold) & (np.arange(len(similarities)) != idiom_index))[0]\n",
    "    \n",
    "    # Sort by similarity (highest first)\n",
    "    similar_indices = similar_indices[np.argsort(similarities[similar_indices])[::-1]]\n",
    "    \n",
    "    # Take top N results\n",
    "    top_indices = similar_indices[:top_n]\n",
    "    \n",
    "    return df.iloc[top_indices], similarities[top_indices]\n",
    "\n",
    "# Example usage\n",
    "example_idiom_index = 13\n",
    "similar_idioms, similarity_scores = find_similar_idioms(example_idiom_index)\n",
    "\n",
    "print(f\"Original Idiom: {df.iloc[example_idiom_index]['Idiom']}\")\n",
    "print(f\"Meaning: {df.iloc[example_idiom_index]['Meaning']}\")\n",
    "print(\"\\nSimilar idioms:\")\n",
    "for (_, row), score in zip(similar_idioms.iterrows(), similarity_scores):\n",
    "    print(f\"\\nIdiom: {row['Idiom']}\")\n",
    "    print(f\"Meaning: {row['Meaning']}\")\n",
    "    print(f\"Similarity score: {score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52ef2161-bf2f-4c08-9313-d69aa3b9b5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'busy' and 'no free time': 0.2436\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Generate embeddings for the phrases\n",
    "phrase1 = \"busy\"\n",
    "phrase2 = \"no free time\"\n",
    "\n",
    "embedding1 = model.encode([phrase1])\n",
    "embedding2 = model.encode([phrase2])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity = cosine_similarity(embedding1, embedding2)[0][0]\n",
    "\n",
    "print(f\"Similarity between '{phrase1}' and '{phrase2}': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e353906f-1c24-49cd-808e-de703a97e29b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ridhibandaru/nltk_data...\n",
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'busy' and 'no free time': 0.2815\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def get_expanded_phrases(phrase):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(phrase):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.add(lemma.name().replace('_', ' '))\n",
    "    return list(synonyms)\n",
    "\n",
    "def get_similarity(phrase1, phrase2, model):\n",
    "    # Get expanded phrases\n",
    "    expanded1 = get_expanded_phrases(phrase1) + [phrase1]\n",
    "    expanded2 = get_expanded_phrases(phrase2) + [phrase2]\n",
    "    \n",
    "    # Generate embeddings\n",
    "    embeddings1 = model.encode(expanded1)\n",
    "    embeddings2 = model.encode(expanded2)\n",
    "    \n",
    "    # Calculate max similarity\n",
    "    similarities = cosine_similarity(embeddings1, embeddings2)\n",
    "    return np.max(similarities)\n",
    "\n",
    "# Load model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Define phrases\n",
    "phrase1 = \"busy\"\n",
    "phrase2 = \"no free time\"\n",
    "\n",
    "# Calculate similarity\n",
    "similarity = get_similarity(phrase1, phrase2, model)\n",
    "\n",
    "print(f\"Similarity between '{phrase1}' and '{phrase2}': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "287ff3cd-9816-45bd-9fee-f3de6bfafdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'busy' and 'no free time': 0.0000\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from conceptnet5.language.english import english_filter\n",
    "import numpy as np\n",
    "\n",
    "def get_conceptnet_related(concept, limit=10):\n",
    "    url = f\"http://api.conceptnet.io/c/en/{concept}?limit={limit}\"\n",
    "    response = json.loads(requests.get(url).text)\n",
    "    related = []\n",
    "    for edge in response['edges']:\n",
    "        if edge['start']['language'] == 'en' and edge['end']['language'] == 'en':\n",
    "            if edge['start']['label'] == concept:\n",
    "                related.append(edge['end']['label'])\n",
    "            else:\n",
    "                related.append(edge['start']['label'])\n",
    "    return list(set(related))\n",
    "\n",
    "def conceptnet_similarity(phrase1, phrase2):\n",
    "    related1 = set(get_conceptnet_related(phrase1))\n",
    "    related2 = set(get_conceptnet_related(phrase2))\n",
    "    \n",
    "    # Add the original phrases to their related sets\n",
    "    related1.add(phrase1)\n",
    "    related2.add(phrase2)\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    intersection = len(related1.intersection(related2))\n",
    "    union = len(related1.union(related2))\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "# Example usage\n",
    "similarity = conceptnet_similarity(\"busy\", \"no free time\")\n",
    "print(f\"Similarity between 'busy' and 'no free time': {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "927e60c8-e6cc-4080-b839-df071167c58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'busy' and 'no free time': 0.0000\n",
      "\n",
      "Concepts related to 'busy':\n",
      "['crowd', 'diligent', 'labouring', 'busy', 'dabble']\n",
      "\n",
      "Concepts related to 'no free time':\n",
      "['hour', 'nary', 'none', 'hours', 'negative', 'uncommitted', 'time', 'unbound', 'clocks', 'No']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "def get_conceptnet_related(concept, limit=20):\n",
    "    url = f\"http://api.conceptnet.io/c/en/{concept.replace(' ', '_')}?limit={limit}\"\n",
    "    response = json.loads(requests.get(url).text)\n",
    "    related = []\n",
    "    for edge in response['edges']:\n",
    "        if edge['start']['language'] == 'en':\n",
    "            related.append(edge['start']['label'])\n",
    "        if edge['end']['language'] == 'en':\n",
    "            related.append(edge['end']['label'])\n",
    "    return list(set(related))\n",
    "\n",
    "def get_expanded_concepts(phrase):\n",
    "    words = phrase.split()\n",
    "    concepts = set()\n",
    "    for word in words:\n",
    "        concepts.update(get_conceptnet_related(word))\n",
    "    concepts.update(get_conceptnet_related(phrase))\n",
    "    return list(concepts)\n",
    "\n",
    "def conceptnet_similarity(phrase1, phrase2):\n",
    "    concepts1 = get_expanded_concepts(phrase1)\n",
    "    concepts2 = get_expanded_concepts(phrase2)\n",
    "    \n",
    "    # Add original phrases and their words\n",
    "    concepts1.extend([phrase1] + phrase1.split())\n",
    "    concepts2.extend([phrase2] + phrase2.split())\n",
    "    \n",
    "    # Count occurrences\n",
    "    counter1 = Counter(concepts1)\n",
    "    counter2 = Counter(concepts2)\n",
    "    \n",
    "    # Calculate cosine similarity\n",
    "    common = set(counter1.keys()) & set(counter2.keys())\n",
    "    numerator = sum(counter1[x] * counter2[x] for x in common)\n",
    "    sum1 = sum(counter1[x]**2 for x in counter1.keys())\n",
    "    sum2 = sum(counter2[x]**2 for x in counter2.keys())\n",
    "    denominator = (sum1 * sum2)**0.5\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    return numerator / denominator\n",
    "\n",
    "# Test the similarity\n",
    "similarity = conceptnet_similarity(\"busy\", \"no free time\")\n",
    "print(f\"Similarity between 'busy' and 'no free time': {similarity:.4f}\")\n",
    "\n",
    "# Let's also print out the related concepts to see what ConceptNet is giving us\n",
    "print(\"\\nConcepts related to 'busy':\")\n",
    "print(get_expanded_concepts(\"busy\")[:10])  # Showing first 10 for brevity\n",
    "\n",
    "print(\"\\nConcepts related to 'no free time':\")\n",
    "print(get_expanded_concepts(\"no free time\")[:10])  # Showing first 10 for brevity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e448e468-899b-4c59-9acf-b983761ef208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid similarity between 'busy' and 'no free time': 1.0000\n",
      "\n",
      "Cluster: raining heavily\n",
      "  - It's raining cats and dogs (raining heavily)\n",
      "\n",
      "Cluster: very busy\n",
      "  - Busy as a bee (very busy)\n",
      "\n",
      "Cluster: no free time\n",
      "  - No time to breathe (no free time)\n",
      "\n",
      "Cluster: time passes quickly\n",
      "  - Time flies (time passes quickly)\n",
      "\n",
      "Cluster: in trouble\n",
      "  - In hot water (in trouble)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from conceptnet5.language.english import english_filter\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# Custom semantic mapping\n",
    "custom_semantic_map = {\n",
    "    \"busy\": [\"occupied\", \"engaged\", \"swamped\", \"no free time\", \"hectic\", \"tied up\"],\n",
    "    \"no free time\": [\"busy\", \"occupied\", \"swamped\", \"hectic\", \"tied up\"],\n",
    "    # Add more mappings as needed\n",
    "}\n",
    "\n",
    "# Load a pre-trained sentence transformer model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "def get_conceptnet_related(concept, limit=10):\n",
    "    url = f\"http://api.conceptnet.io/c/en/{concept.replace(' ', '_')}?limit={limit}\"\n",
    "    response = json.loads(requests.get(url).text)\n",
    "    related = []\n",
    "    for edge in response['edges']:\n",
    "        if edge['start']['language'] == 'en':\n",
    "            related.append(edge['start']['label'])\n",
    "        if edge['end']['language'] == 'en':\n",
    "            related.append(edge['end']['label'])\n",
    "    return list(set(related))\n",
    "\n",
    "def custom_similarity(phrase1, phrase2):\n",
    "    if phrase2 in custom_semantic_map.get(phrase1, []) or phrase1 in custom_semantic_map.get(phrase2, []):\n",
    "        return 1.0\n",
    "    return 0.0\n",
    "\n",
    "def conceptnet_similarity(phrase1, phrase2):\n",
    "    related1 = set(get_conceptnet_related(phrase1))\n",
    "    related2 = set(get_conceptnet_related(phrase2))\n",
    "    \n",
    "    # Add the original phrases to their related sets\n",
    "    related1.add(phrase1)\n",
    "    related2.add(phrase2)\n",
    "    \n",
    "    # Calculate Jaccard similarity\n",
    "    intersection = len(related1.intersection(related2))\n",
    "    union = len(related1.union(related2))\n",
    "    \n",
    "    return intersection / union if union > 0 else 0\n",
    "\n",
    "def embedding_similarity(phrase1, phrase2):\n",
    "    emb1 = model.encode([phrase1])[0]\n",
    "    emb2 = model.encode([phrase2])[0]\n",
    "    return np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "\n",
    "def hybrid_similarity(phrase1, phrase2):\n",
    "    custom_sim = custom_similarity(phrase1, phrase2)\n",
    "    if custom_sim > 0:\n",
    "        return custom_sim\n",
    "    \n",
    "    cn_sim = conceptnet_similarity(phrase1, phrase2)\n",
    "    emb_sim = embedding_similarity(phrase1, phrase2)\n",
    "    \n",
    "    return max(cn_sim, emb_sim)\n",
    "\n",
    "# Test the hybrid similarity\n",
    "similarity = hybrid_similarity(\"busy\", \"no free time\")\n",
    "print(f\"Hybrid similarity between 'busy' and 'no free time': {similarity:.4f}\")\n",
    "\n",
    "# Function to cluster idioms\n",
    "def cluster_idioms(idioms, meanings, similarity_threshold=0.7):\n",
    "    clusters = {}\n",
    "    \n",
    "    for i, (idiom, meaning) in enumerate(zip(idioms, meanings)):\n",
    "        added_to_cluster = False\n",
    "        \n",
    "        for cluster_key in clusters:\n",
    "            if hybrid_similarity(meaning, cluster_key) > similarity_threshold:\n",
    "                clusters[cluster_key].append((idiom, meaning))\n",
    "                added_to_cluster = True\n",
    "                break\n",
    "        \n",
    "        if not added_to_cluster:\n",
    "            clusters[meaning] = [(idiom, meaning)]\n",
    "    \n",
    "    return clusters\n",
    "\n",
    "# Example usage\n",
    "idioms = [\n",
    "    \"It's raining cats and dogs\",\n",
    "    \"Busy as a bee\",\n",
    "    \"No time to breathe\",\n",
    "    \"Time flies\",\n",
    "    \"In hot water\"\n",
    "]\n",
    "meanings = [\n",
    "    \"raining heavily\",\n",
    "    \"very busy\",\n",
    "    \"no free time\",\n",
    "    \"time passes quickly\",\n",
    "    \"in trouble\"\n",
    "]\n",
    "\n",
    "idiom_clusters = cluster_idioms(idioms, meanings)\n",
    "\n",
    "for cluster_key, cluster_items in idiom_clusters.items():\n",
    "    print(f\"\\nCluster: {cluster_key}\")\n",
    "    for idiom, meaning in cluster_items:\n",
    "        print(f\"  - {idiom} ({meaning})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f812336d-800d-412a-a17f-5497e012e173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21891384\n",
      "0.38433766\n"
     ]
    }
   ],
   "source": [
    "print(hybrid_similarity(\"very busy\", \"no free time\"))\n",
    "print(hybrid_similarity(\"time passes quickly\", \"no free time\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bebab7-d75e-4fe1-af4b-4768377ed972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed68b129-9de3-499a-acb5-26f018539260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
